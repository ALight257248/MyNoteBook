{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3c8f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee9287d",
   "metadata": {},
   "source": [
    "# 数据类型\n",
    "torch一共有两套数据类型，分别为在GPU上运行与不在GPU上运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d04b131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.DoubleTensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.IntTensor\n",
    "torch.LongTensor\n",
    "torch.ByteTensor\n",
    "torch.FloatTensor\n",
    "torch.DoubleTensor\n",
    "# 如果为在GPU上面运行，则为torch.cuda.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24be7b67",
   "metadata": {},
   "source": [
    "# 判断tensor的类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a00e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3)\n",
    "print(a.type())\n",
    "print(isinstance(a, torch.FloatTensor))\n",
    "print(isinstance(a, torch.cuda.FloatTensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab42bc70",
   "metadata": {},
   "source": [
    "# 不同维度的tensor的创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acea4128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "torch.Size([])\n",
      "torch.Size([])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Dimension which is 0, is named vector\n",
    "# It is often used fro Loss\n",
    "a = torch.tensor(1)\n",
    "a.type = torch.FloatTensor\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.size())\n",
    "print(len(a.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47993b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1000, 2.2000])\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Dimension which is 1, is named vector. tensor is named here\n",
    "# It is often used for Bias\n",
    "# It is also used for Linear Input\n",
    "a = torch.FloatTensor([1.1, 2.2])\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.size())\n",
    "print(len(a.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1914c3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7463e+00,  6.3281e-01, -9.4935e-04],\n",
      "        [-3.0621e-01, -5.8350e-01, -6.2130e-01]])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Dimension which is 2\n",
    "a = torch.randn(2, 3)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.size())\n",
    "print(len(a.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05c2f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2671, 0.2908, 0.5051],\n",
      "         [0.1113, 0.8172, 0.5334]]])\n",
      "torch.Size([1, 2, 3])\n",
      "torch.Size([1, 2, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Dimension which is 3\n",
    "# It is often used for RNN, which is made for NLP\n",
    "a = torch.rand(1, 2, 3)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.size())\n",
    "print(len(a.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c56bb95",
   "metadata": {},
   "source": [
    "# 工具类shape, numel(), dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6f1dd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 28, 28])\n",
      "4704\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 3, 28, 28)\n",
    "# shape，查看tensor的形状\n",
    "print(a.shape)\n",
    "# numel(), 查看数据所占空间的大小，number of element\n",
    "print(a.numel())\n",
    "# dim(), 查看tensor的维度\n",
    "print(a.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81306425",
   "metadata": {},
   "source": [
    "# 创建tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370a3ef",
   "metadata": {},
   "source": [
    "## 使用numpy创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8debd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 4], dtype=torch.int32)\n",
      "torch.Size([3])\n",
      "torch.IntTensor\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2, 3, 4])\n",
    "a = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166db9bd",
   "metadata": {},
   "source": [
    "## 使用list导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66fbeff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5963e+20, 3.3587e-06, 2.6657e-09],\n",
      "        [2.1061e+23, 1.7203e-04, 1.7470e-04]])\n",
      "torch.Size([2, 3])\n",
      "torch.FloatTensor\n",
      "tensor([2.0000, 3.2000])\n",
      "torch.Size([2])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Tensor给维度（其实也可以给数据）\n",
    "# tensor给现成的数据\n",
    "a = torch.Tensor(2, 3)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.type())\n",
    "b = torch.tensor([2, 3.2])\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(b.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ddd2c",
   "metadata": {},
   "source": [
    "## 使用torch.rand()进行随机采样\n",
    "> 在[0, 1]之间随机采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd05910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8273, 0.1000, 0.4997],\n",
      "        [0.5372, 0.5678, 0.5191]])\n",
      "torch.Size([2, 3])\n",
      "torch.FloatTensor\n",
      "tensor([[0.0678, 0.3657, 0.4223],\n",
      "        [0.4250, 0.1339, 0.3958]])\n",
      "torch.Size([2, 3])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.type())\n",
    "# like的使用\n",
    "y = torch.rand_like(x)\n",
    "print(y)\n",
    "print(y.shape)\n",
    "print(y.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5fb34",
   "metadata": {},
   "source": [
    "## 使用torch.randn()进行正态分布随机采样\n",
    "> randn采样依照正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e56ddd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3734,  0.1140, -1.0860],\n",
      "        [-0.7562, -1.4560,  0.8491],\n",
      "        [-0.7876,  0.8743,  0.1920]])\n",
      "torch.Size([3, 3])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3, 3)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10091f2",
   "metadata": {},
   "source": [
    "## 使用torch.randint()创建整数范围内的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43e04176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 4, 3],\n",
      "        [7, 6, 7],\n",
      "        [4, 8, 2]])\n",
      "torch.Size([3, 3])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(1, 10, [3, 3])\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98985f03",
   "metadata": {},
   "source": [
    "## 使用torch.full()创建一个由相同元素组成的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edf592e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 7, 7],\n",
      "        [7, 7, 7]])\n",
      "torch.Size([2, 3])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "a = torch.full([2, 3], 7)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6429b1d",
   "metadata": {},
   "source": [
    "## torch.arange()创建一个连续的一维tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b639a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "torch.Size([9])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# [1, 10)\n",
    "a = torch.arange(1, 10)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394530f9",
   "metadata": {},
   "source": [
    "## torch.linspace()与torch.logspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f658b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  1.1111,  2.2222,  3.3333,  4.4444,  5.5556,  6.6667,  7.7778,\n",
      "         8.8889, 10.0000])\n",
      "torch.Size([10])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# linspace 从0到10分割为10份\n",
    "a = torch.linspace(0, 10 ,steps=10)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c532ef51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.7743, 0.5995, 0.4642, 0.3594, 0.2783, 0.2154, 0.1668, 0.1292,\n",
      "        0.1000])\n",
      "torch.Size([10])\n",
      "torch.FloatTensor\n",
      "tensor([1.0000, 0.9259, 0.8572, 0.7937, 0.7349, 0.6804, 0.6300, 0.5833, 0.5400,\n",
      "        0.5000])\n",
      "torch.Size([10])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# logspace 从10^0到10^-1分成10份，同时还可以改变base\n",
    "a = torch.logspace(0, -1, steps=10)\n",
    "b = torch.logspace(0, -1, steps=10, base=2)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.type())\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(b.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b04e29",
   "metadata": {},
   "source": [
    "## 使用torch.ones()和torch.zeros()以及torch.eye(）创建tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f61026be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 这个也以torch.*_like()\n",
    "print(torch.ones(3 ,3))\n",
    "print(torch.zeros(3, 3))\n",
    "print(torch.eye(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83737838",
   "metadata": {},
   "source": [
    "## 使用torch.randperm()生成打乱的下标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2662aa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 5, 4, 2, 3, 8, 9, 7, 6])\n"
     ]
    }
   ],
   "source": [
    "#生成打乱的0到9\n",
    "print(torch.randperm(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3588ec",
   "metadata": {},
   "source": [
    "# 对tensor进行索引以及切片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c9725c",
   "metadata": {},
   "source": [
    "## 索引的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b88d8035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([28, 28])\n",
      "torch.Size([2, 3, 28, 28])\n",
      "torch.Size([2, 2, 28, 28])\n",
      "torch.Size([2, 3, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 3, 28, 28)\n",
    "print(a[0].shape)\n",
    "print(a[0, 1].shape)\n",
    "print(a[:2].shape)\n",
    "print(a[:2, :-1].shape)\n",
    "print(a[:2, :, 0::2, 0::2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895194e5",
   "metadata": {},
   "source": [
    "## torch.index_select(input, dim, index, out=None)进行tensor的切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf54c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(0, 9)\n",
    "print(a)\n",
    "# 获取tensor a的第一个维度且索引号为2和3的张量子集\n",
    "print(torch.index_select(a, dim=0, index=torch.tensor([2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "633681e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[0, 1],\n",
      "        [3, 4],\n",
      "        [6, 7]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.arange(0, 9).view([3, 3])\n",
    "print(b)\n",
    "# 获取tensor b的第二个维度的索引号为0和1的张量子集\n",
    "print(torch.index_select(b, dim=1, index=torch.tensor([0, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48605d0c",
   "metadata": {},
   "source": [
    "## 用...表示任意多的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad469fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3, 4, 5])\n",
      "torch.Size([1, 2, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(1, 10, [1, 2, 3, 4, 5])\n",
    "print(a.shape)\n",
    "print(a[..., :-1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35766bbd",
   "metadata": {},
   "source": [
    "## 使用masked_select()通过mask选择相应位置的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "508282c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1300, -0.0698,  1.0953, -0.2350],\n",
      "        [-2.9467, -1.2536, -1.2334,  0.3912],\n",
      "        [-0.1170,  0.8351, -0.1934, -0.1575]])\n",
      "tensor([[ True, False,  True, False],\n",
      "        [False, False, False, False],\n",
      "        [False,  True, False, False]])\n",
      "tensor([1.1300, 1.0953, 0.8351])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4)\n",
    "print(x)\n",
    "mask = x.ge(0.5)\n",
    "print(mask)\n",
    "print(torch.masked_select(x, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83274cd7",
   "metadata": {},
   "source": [
    "## 使用take将数据打一维后，按照索引选取元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce495fcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([4, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "src = torch.tensor([[4, 3, 5],                   [6, 7, 8]])\n",
    "print(src.shape)\n",
    "print(torch.take(src, torch.tensor([0, 2, 5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8102a",
   "metadata": {},
   "source": [
    "# 维度变换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d2a7cb",
   "metadata": {},
   "source": [
    "## 使用view进行维度的变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "362ea57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n",
      "torch.Size([4, 784])\n",
      "torch.Size([112, 28])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 1, 28, 28)\n",
    "print(a.shape)\n",
    "print(a.view(4, 28*28).shape)\n",
    "print(a.view(4*28, 28).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8add15",
   "metadata": {},
   "source": [
    "## 使用squeeze()进行维度的挤压\n",
    "> 压缩的时候，会将1维度压缩，但是如果维度不是1，就会爆出不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dd2528e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 28, 28])\n",
      "torch.Size([4, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 1, 28, 28)\n",
    "print(a.squeeze().shape)\n",
    "print(a.squeeze(1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d71f4",
   "metadata": {},
   "source": [
    "## 使用unsqueeze()进行维度扩张"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9db5a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(4, 28, 28)\n",
    "print(a.unsqueeze(1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2552a12",
   "metadata": {},
   "source": [
    "## 使用expand()进行维度的扩张"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c37a4ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 1])\n",
      "torch.Size([2, 10, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 1, 1)\n",
    "print(a.shape)\n",
    "print(a.expand(2, 10, 1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c0bb5",
   "metadata": {},
   "source": [
    "## 使用repeat()进行维度的扩张\n",
    ">沿着指定的维度重复tensor。不同与expand()，本函数复制的是tensor中的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2df86fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2409],\n",
      "        [0.6011]])\n",
      "tensor([[0.2409, 0.2409],\n",
      "        [0.6011, 0.6011],\n",
      "        [0.2409, 0.2409],\n",
      "        [0.6011, 0.6011]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 1)\n",
    "b = a.repeat(2, 2)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799ad26",
   "metadata": {},
   "source": [
    "## 使用.t()进行矩阵的转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed47d350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 3],\n",
      "        [2, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2],\n",
    "                 [3, 4]])\n",
    "print(a)\n",
    "print(a.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19514727",
   "metadata": {},
   "source": [
    "## 使用transpose()进行维度的交换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bc0d351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3132, 0.4367]])\n",
      "torch.Size([1, 2])\n",
      "tensor([[0.3132],\n",
      "        [0.4367]])\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1, 2)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "b = a.transpose(0, 1)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ee49f",
   "metadata": {},
   "source": [
    "## 使用permute()进行tensor维度换位\n",
    "> 与transpose相比，permute可以用于高维矩阵的转换，而transpose只能进行二维矩阵的置换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdfb6965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 5)\n",
    "print(x.shape)\n",
    "print(x.permute(2, 0, 1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d3c3c3",
   "metadata": {},
   "source": [
    "## 关于contiguous\n",
    "https://zhuanlan.zhihu.com/p/64551412\n",
    "> contiguous的作用是让tensor的内存变得连续\n",
    "\n",
    "为什么需要contiguous?\n",
    "1. torch.view等操作需要连续的Tensor\n",
    "2. 处于性能的考虑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e66b72",
   "metadata": {},
   "source": [
    "# BroadCasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf45548",
   "metadata": {},
   "source": [
    "# 合并与分割"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f937c",
   "metadata": {},
   "source": [
    "# 数学运算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef73379",
   "metadata": {},
   "source": [
    "# 统计属性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce246bb0",
   "metadata": {},
   "source": [
    "## 使用norm()求范数\n",
    "1. Vector norm\n",
    "$$\n",
    "||x||_{p} = (\\sum_{i=1}^{n}{|x_i|}^{p})^{1/p}\n",
    "$$\n",
    "2. Matrix norm\n",
    "    \n",
    "    1-范数：\n",
    "$$\n",
    "||A||_1 = \\mathop{max}\\limits_{j}\\sum_{i=1}^{n}|a_{i,j}|\n",
    "$$\n",
    "    2-范数：\n",
    "$$\n",
    "||A||_2 = \\sqrt{\\lambda_1} \\quad\\quad[其中\\lambda为A^TA的最大特征值]\n",
    "$$\n",
    "F-范数：Frobenius范数，即矩阵元素绝对值的平方和再开方\n",
    "$$\n",
    "||A||_F = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}|a_{i, j}|^2)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2a2a157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x00000191594C6548>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(8.), tensor(8.), tensor(8.))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.full([8], 1.)\n",
    "print(a.type)\n",
    "b = a.view(2, 4)\n",
    "c = a. view(2, 2, 2)\n",
    "# 求a, b, c的1-范式\n",
    "a.norm(1), b.norm(1), c.norm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17ebb563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.8284), tensor(2.8284), tensor(2.8284))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求a, b, c的2-范式\n",
    "a.norm(2), b.norm(2), c.norm(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9ff719f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 4.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对b的一维度求1-范数\n",
    "b.norm(1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd9583a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4142, 1.4142, 1.4142, 1.4142])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对b的一维度求2-范数\n",
    "b.norm(2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a3b2004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对哪个维度求范数，得到的结果的shape是消去这个维度的shape\n",
    "c.norm(1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3596bfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4142, 1.4142],\n",
       "        [1.4142, 1.4142]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.norm(2, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea3c3d2",
   "metadata": {},
   "source": [
    "## mean，sum，min，max，prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "191ce7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(7.), tensor(3.5000), tensor(0.), tensor(28.))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(8).view(2,4).float()\n",
    "# prod返回新的张量，其中包括输入张量input中指定维度dim中每行的乘积\n",
    "a.min(), a.max(), a.mean(), a.prod(), a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "351ee469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) tensor(0)\n",
      "tensor([[0., 1., 2., 3.],\n",
      "        [4., 5., 6., 7.]])\n",
      "tensor([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "#注意这个结果，是原来的tensor打平后的索引\n",
    "print(a.argmax(), a.argmin())\n",
    "#如果要求某一个维度的索引，加上dim\n",
    "print(a)\n",
    "print(a.argmax(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479d8d9",
   "metadata": {},
   "source": [
    "## dim, keepdim\n",
    ">keepdim保持dimension不发生变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d6451f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([2.3888, 1.3834, 1.2374, 1.8031]),\n",
      "indices=tensor([2, 5, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4, 10)\n",
    "# 出来的结果，前者为最大值，后面是对应的索引\n",
    "print(a.max(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38d8093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# keepdim的使用\n",
    "print(a.max(dim=1).values.shape)\n",
    "print(a.max(dim=1, keepdim=True).values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b25021",
   "metadata": {},
   "source": [
    "## topk, kthvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da550054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8, 9, 0, 6, 2],\n",
      "        [1, 5, 7, 4, 3]])\n",
      "torch.return_types.topk(\n",
      "values=tensor([[9, 8, 6],\n",
      "        [7, 5, 4]]),\n",
      "indices=tensor([[1, 0, 3],\n",
      "        [2, 1, 3]]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([[0, 2, 6],\n",
      "        [1, 3, 4]]),\n",
      "indices=tensor([[2, 4, 3],\n",
      "        [0, 4, 3]]))\n"
     ]
    }
   ],
   "source": [
    "a = torch.randperm(10).view(2, 5)\n",
    "print(a)\n",
    "# 找到某个维度下最大的k个数\n",
    "print(a.topk(3, dim=1))\n",
    "# 找到某个维度下最小的k个数\n",
    "print(a.topk(3, dim=1, largest=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81f8107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8, 9, 0, 6, 2],\n",
      "        [1, 5, 7, 4, 3]])\n",
      "torch.return_types.kthvalue(\n",
      "values=tensor([0, 1]),\n",
      "indices=tensor([2, 0]))\n"
     ]
    }
   ],
   "source": [
    "# kthvalue默认为最小，并且不可以改变, 找到第k小并且返回\n",
    "print(a)\n",
    "print(a.kthvalue(1, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeef7e3",
   "metadata": {},
   "source": [
    "## compare的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4decbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >, >=, <, <=, !=, =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27515e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# eq和equal他们前者返回每一位是否相同，后者返回整体是否相同\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = a\n",
    "print(torch.eq(a, b))\n",
    "print(torch.equal(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fdcd55",
   "metadata": {},
   "source": [
    "# 高阶操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7133d84",
   "metadata": {},
   "source": [
    "## torch.where(condition, x, y)\n",
    "> 从x和y中选择来源，返回一个新的tensor.\n",
    "> 其中condition是一个选择，是true or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb3b2038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = torch.tensor([[0.6, 0.7],\n",
    "                    [0.8, 0.4]])\n",
    "b = torch.ones(2, 2)\n",
    "a = torch.zeros(2, 2)\n",
    "torch.where(cond>0.5, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77069cb",
   "metadata": {},
   "source": [
    "## torch.gather(input, dim, index, out=None) →Tensor\n",
    "> Gathers values along an axis specified by dim \\\n",
    "查表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b3cae55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4792, 0.0788, 0.1425, 0.3935, 0.1943, 0.2078, 0.6045, 0.9608, 0.5853,\n",
      "         0.9396],\n",
      "        [0.7473, 0.1507, 0.8077, 0.4284, 0.1259, 0.3927, 0.4057, 0.9557, 0.6745,\n",
      "         0.1057],\n",
      "        [0.2822, 0.6394, 0.3679, 0.8634, 0.7002, 0.4668, 0.8619, 0.0093, 0.8775,\n",
      "         0.2737],\n",
      "        [0.8357, 0.2650, 0.0732, 0.4544, 0.3893, 0.3816, 0.5751, 0.8035, 0.1881,\n",
      "         0.6178]])\n",
      "tensor([[7, 9, 6],\n",
      "        [7, 2, 0],\n",
      "        [8, 3, 6],\n",
      "        [0, 7, 9]])\n",
      "tensor([100, 101, 102, 103, 104, 105, 106, 107, 108, 109])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[107, 109, 106],\n",
       "        [107, 102, 100],\n",
       "        [108, 103, 106],\n",
       "        [100, 107, 109]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = torch.rand(4, 10)\n",
    "print(prob)\n",
    "idx = prob.topk(dim=1, k=3)[1]\n",
    "print(idx)\n",
    "label = torch.arange(10)+100\n",
    "print(label)\n",
    "torch.gather(label.expand(4, 10), dim=1, index=idx.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb7aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
